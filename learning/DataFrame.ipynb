{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P5lMZdt8c8B"
      },
      "outputs": [],
      "source": [
        "# importing necessary liberaries\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any PySpark application starts with createing the pyspark session, which is the entry point for that application."
      ],
      "metadata": {
        "id": "aU5LGuKj8--P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('LearningApplication').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "s-C1dcKr8l4e",
        "outputId": "b35522b6-7afd-4988-b3ca-a89e3ad024e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a4192126bf0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c8a835427ee4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>LearningApplication</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Spark Datafame\n",
        "Spark data frame can be created by using createDataFrame() function from SparkSession. Parameter to this function can be lists, tuples, dictionaries, or pyspark.sql.Row. You can specefy the schema by yourself or by default, it will infer existing schema from data.\n",
        "\n",
        "The following code illustrates:\n",
        "* creating spark dataframe with list of tuples\n",
        "* creating spark dataframe with spark.SparkSession.Row: with and without explicit schema\n",
        "* createing spark dataframe with pandas dataframe"
      ],
      "metadata": {
        "id": "Rvr3_chc9eGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of tuples\n",
        "df1 = [('James','','Smith','1991-04-01','M',3000),\n",
        "  ('Michael','Rose','','2000-05-19','M',4000),\n",
        "  ('Robert','','Williams','1978-09-05','M',4000),\n",
        "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
        "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
        "]\n",
        "\n",
        "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
        "df1 = spark.createDataFrame(data=df1, schema = columns)\n",
        "\n",
        "# viewing dataframe\n",
        "df1.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "VsxbdkPU9NGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55ff3ec-72b3-4fd0-cefe-2d01476c3e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#createing spark dataframe using spark.SparkSession.Row\n",
        "from pyspark.sql import Row\n",
        "\n",
        "df2 = spark.createDataFrame([\n",
        "    Row(firstname='James',middlename='',lastname='Smith',dob='1991-04-01',gender='M',salary=3000),\n",
        "    Row(firstname='Robert',middlename='',lastname='Williams',dob='1978-09-05',gender='M',salary=4000),\n",
        "    Row(firstname='Satish',middlename='',lastname='Kandel',dob='1998-04-01',gender='M',salary=5000)\n",
        "])\n",
        "df2"
      ],
      "metadata": {
        "id": "u6rPrv5h_Zk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4de7c2-ce31-4024-ebcf-8e272c33758f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[firstname: string, middlename: string, lastname: string, dob: string, gender: string, salary: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# createing spark dataframe using explicit schema\n",
        "from datetime import date,datetime\n",
        "df2 = spark.createDataFrame([\n",
        "    Row(firstname='James',middlename='',lastname='Smith',dob=datetime.strptime('1991-04-01','%Y-%m-%d'),gender='M',salary=3000),\n",
        "    Row(firstname='Robert',middlename='',lastname='Williams',dob=datetime.strptime('1978-09-05','%Y-%m-%d'),gender='M',salary=4000),\n",
        "    Row(firstname='Satish',middlename='',lastname='Kandel',dob=datetime.strptime('1998-04-01','%Y-%m-%d'),gender='M',salary=5000)\n",
        "],schema='firstname string,middlename string,lastname string,dob date,gender string,salary int')\n",
        "df2.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PesCoDVSBd5S",
        "outputId": "9a019a55-656a-4cab-bcce-77679eda2279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a spark dataframe with pandas dataframe\n",
        "import pandas as pd\n",
        "df=pd.DataFrame({'firstname':['James','Robert','Satish'],\n",
        "                 'middlename':['','',''],\n",
        "                 'lastname':['Smith','Williams','Kandel'],\n",
        "                 'dob':['1991-04-01','1978-09-05','1998-04-01'],\n",
        "                 'gender':['M','M','M'],\n",
        "                 'salary':[3000,4000,5000]\n",
        "                 })\n",
        "\n",
        "df3=spark.createDataFrame(df)\n",
        "df3.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPjAJZOxCaE5",
        "outputId": "94705830-bbc7-4b68-8c8a-f14c3ddc7d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to see data in vertical manner\n",
        "df3.show(vertical=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4Hnwt3HEaNm",
        "outputId": "dd7da7e4-f449-4d01-b4ca-66e67580ab27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0----------------\n",
            " firstname  | James      \n",
            " middlename |            \n",
            " lastname   | Smith      \n",
            " dob        | 1991-04-01 \n",
            " gender     | M          \n",
            " salary     | 3000       \n",
            "-RECORD 1----------------\n",
            " firstname  | Robert     \n",
            " middlename |            \n",
            " lastname   | Williams   \n",
            " dob        | 1978-09-05 \n",
            " gender     | M          \n",
            " salary     | 4000       \n",
            "-RECORD 2----------------\n",
            " firstname  | Satish     \n",
            " middlename |            \n",
            " lastname   | Kandel     \n",
            " dob        | 1998-04-01 \n",
            " gender     | M          \n",
            " salary     | 5000       \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for the schema\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvvN5OYqFi1m",
        "outputId": "6c28deea-dd85-42af-df4b-881c011a481a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0MlXWZ5Fr1E",
        "outputId": "d8a9528f-bbd4-4669-849f-441a01171be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['firstname', 'middlename', 'lastname', 'dob', 'gender', 'salary']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the summery count of the data by selecting only specefic columns from the dataframe\n",
        "df3.select('firstname','lastname').describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJzrkGXWFvI3",
        "outputId": "679dd49d-5b63-4a35-d12b-caa8bdefbdd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+--------+\n",
            "|summary|firstname|lastname|\n",
            "+-------+---------+--------+\n",
            "|  count|        3|       3|\n",
            "|   mean|     NULL|    NULL|\n",
            "| stddev|     NULL|    NULL|\n",
            "|    min|    James|  Kandel|\n",
            "|    max|   Satish|Williams|\n",
            "+-------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select only few columns from the dataframe\n",
        "df3.select('firstname').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0LrMgb1F6oX",
        "outputId": "3f802257-da15-4c42-b6a4-697bc86965cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|firstname|\n",
            "+---------+\n",
            "|    James|\n",
            "|   Robert|\n",
            "|   Satish|\n",
            "+---------+\n",
            "\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df3))\n",
        "print(type(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMWQh28TGKMG",
        "outputId": "21dade5b-890b-4fc6-f552-f2282ecf12b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark dataframe are built on the top of RDD. By default spark dataframe are lazy evaluated, when the spark transform the data, it doesnot computes the transformation immediately, instead, it plans how to compute latter. However, this default behaviour can be confugured by using the folllowing spark command."
      ],
      "metadata": {
        "id": "l2Fchq2aG4Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
        "spark.conf.set('spark.sql.repl.eagerEval.maxNumRows', 10)  #controls the maximum number of the rows shown at a time."
      ],
      "metadata": {
        "id": "62uSQ4JhGhnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PySpark, the collect() function is used to retrieve all the elements (rows) of a DataFrame (or RDD) from the distributed cluster to the local driver(driver node). It collects the data from the Spark workers, gathers it into a list, and returns it to the driver."
      ],
      "metadata": {
        "id": "AUC908dOJIrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFbqODESI98X",
        "outputId": "11aba8f7-cad9-4edb-e4ab-72dbfff80ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(firstname='James', middlename='', lastname='Smith', dob='1991-04-01', gender='M', salary=3000),\n",
              " Row(firstname='Michael', middlename='Rose', lastname='', dob='2000-05-19', gender='M', salary=4000),\n",
              " Row(firstname='Robert', middlename='', lastname='Williams', dob='1978-09-05', gender='M', salary=4000),\n",
              " Row(firstname='Maria', middlename='Anne', lastname='Jones', dob='1967-12-01', gender='F', salary=4000),\n",
              " Row(firstname='Jen', middlename='Mary', lastname='Brown', dob='1980-02-17', gender='F', salary=-1)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in order to deal with out-of-memory, we can using take(2), or tail(1)\n",
        "df1.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YymBnmdCHnIL",
        "outputId": "377d690f-a24c-46be-902e-eda3d51f91f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(firstname='James', middlename='', lastname='Smith', dob='1991-04-01', gender='M', salary=3000),\n",
              " Row(firstname='Michael', middlename='Rose', lastname='', dob='2000-05-19', gender='M', salary=4000)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.tail(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoiEykiNSW2L",
        "outputId": "a420692e-a9a1-4c42-c4a5-ea7004416c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(firstname='Jen', middlename='Mary', lastname='Brown', dob='1980-02-17', gender='F', salary=-1)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting back to pandas dataframe\n",
        "df3.toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "_6MTZADUScGQ",
        "outputId": "4abf42ee-ae56-4369-cb25-30dafac755d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     James\n",
              "1    Robert\n",
              "2    Satish\n",
              "Name: firstname, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>firstname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>James</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Robert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Satish</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this will return column\n",
        "df3.toPandas().firstname"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "3T92MixEYQA2",
        "outputId": "0be0031f-c596-4c4c-b0a0-e15017f18724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     James\n",
              "1    Robert\n",
              "2    Satish\n",
              "Name: firstname, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>firstname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>James</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Robert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Satish</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting and Accessing Data\n"
      ],
      "metadata": {
        "id": "f0sKJoY6Xokz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since spark data frame are lazy evaluated, when you access the column it returns the column instance\n",
        "# this will return column instance\n",
        "df2.firstname"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGRuU-RoXlU1",
        "outputId": "bcd54e80-a015-4cd8-bad2-19218ef19360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'firstname'>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Column\n",
        "from pyspark.sql.functions import upper"
      ],
      "metadata": {
        "id": "fcG7mkRBX0RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df3.firstname) == type(upper(df3.firstname)) == type(df3.firstname.isNull())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udl74s_3ZRXe",
        "outputId": "70729b20-ebd9-4b28-e47d-9b4b93df7e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# different ways to access the columns\n",
        "df3.select(df3.firstname).show()\n",
        "df3.select(\"firstname\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gflI8ygZV_x",
        "outputId": "01c9dd3c-f75b-403e-a946-5c823e890a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|firstname|\n",
            "+---------+\n",
            "|    James|\n",
            "|   Robert|\n",
            "|   Satish|\n",
            "+---------+\n",
            "\n",
            "+---------+\n",
            "|firstname|\n",
            "+---------+\n",
            "|    James|\n",
            "|   Robert|\n",
            "|   Satish|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# createing the new column to the spark dataframe\n",
        "df3.withColumn('new_salary',df3.salary*2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIzbk8otZv-P",
        "outputId": "9d947d51-58b0-4166-bba1-b75bf85ba910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+----------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|new_salary|\n",
            "+---------+----------+--------+----------+------+------+----------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|      6000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|      8000|\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|     10000|\n",
            "+---------+----------+--------+----------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting data of the column to upper case as a new column\n",
        "df3.withColumn('upper_firstname',upper(df3.firstname)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h83geEuOabu7",
        "outputId": "c2846b69-a1d8-4366-ab2e-636b42703fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+---------------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|upper_firstname|\n",
            "+---------+----------+--------+----------+------+------+---------------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|          JAMES|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|         ROBERT|\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|         SATISH|\n",
            "+---------+----------+--------+----------+------+------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering the rows\n",
        "df3.filter(df3.firstname=='Satish').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r296k1I0asjM",
        "outputId": "a3a1f4f7-8427-4b47-98a0-ffb48db3c74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lower\n",
        "df3.filter(lower(df3.firstname)=='satish').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f3xDEb-a2LC",
        "outputId": "1c841b32-6e36-401a-8c17-a08161f3fb56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying a Function\n",
        "In the pyspark, we can apply different functions to the dataframe, these functions can be userdefined functions(UDF), python built in functions or Pandas UDFs. These functions allows us to transoform, manupulate and perform calculations on the data"
      ],
      "metadata": {
        "id": "PEWOe-mNbNYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to concatenate every column to the single column\n",
        "def concat_columns(firstname,middlename,lastname):\n",
        "    return firstname+' '+middlename+' '+lastname\n",
        "\n",
        "# function to increase the salary\n",
        "def increase_salary(salary):\n",
        "    return salary*2"
      ],
      "metadata": {
        "id": "BviJWLuibQsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying both of the functions to spark dataframe\n",
        "df3.withColumn(\"fullname\",concat_columns(df3.firstname,df3.middlename,df3.lastname)).withColumn('new_salary',increase_salary(df3.salary)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzO-VOcUcv1x",
        "outputId": "79222a2d-2ada-4e78-c11a-758af358ab66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+--------+----------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|fullname|new_salary|\n",
            "+---------+----------+--------+----------+------+------+--------+----------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|    NULL|      6000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|    NULL|      8000|\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|    NULL|     10000|\n",
            "+---------+----------+--------+----------+------+------+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import pandas_udf\n",
        "\n",
        "@pandas_udf('long')\n",
        "def pandas_plus_one(series: pd.Series) -> pd.Series:\n",
        "    # add one by using pandas series\n",
        "    return series + 1\n",
        "\n",
        "df3.select(pandas_plus_one(df3.salary)).show() #doesnot change the dataframe yet\n",
        "df3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "FWAxgBRHdLRA",
        "outputId": "92225eb0-72a8-4c65-850e-ef90c7704775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+\n",
            "|pandas_plus_one(salary)|\n",
            "+-----------------------+\n",
            "|                   3001|\n",
            "|                   4001|\n",
            "|                   5001|\n",
            "+-----------------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+----------+--------+----------+------+------+\n",
              "|firstname|middlename|lastname|       dob|gender|salary|\n",
              "+---------+----------+--------+----------+------+------+\n",
              "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
              "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
              "|   Satish|          |  Kandel|1998-04-01|     M|  5000|\n",
              "+---------+----------+--------+----------+------+------+"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>firstname</th><th>middlename</th><th>lastname</th><th>dob</th><th>gender</th><th>salary</th></tr>\n",
              "<tr><td>James</td><td></td><td>Smith</td><td>1991-04-01</td><td>M</td><td>3000</td></tr>\n",
              "<tr><td>Robert</td><td></td><td>Williams</td><td>1978-09-05</td><td>M</td><td>4000</td></tr>\n",
              "<tr><td>Satish</td><td></td><td>Kandel</td><td>1998-04-01</td><td>M</td><td>5000</td></tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting columns by different ways\n",
        "df3.select(\"firstname\",\"lastname\").show()\n",
        "df3.select(df3.firstname,df3.lastname).show()\n",
        "df3.select(df3[\"firstname\"],df3[\"lastname\"]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F_Y6nFaefwO",
        "outputId": "957cf3f4-4bb5-4350-fd94-84f8e9fbbee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|    James|   Smith|\n",
            "|   Robert|Williams|\n",
            "|   Satish|  Kandel|\n",
            "+---------+--------+\n",
            "\n",
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|    James|   Smith|\n",
            "|   Robert|Williams|\n",
            "|   Satish|  Kandel|\n",
            "+---------+--------+\n",
            "\n",
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|    James|   Smith|\n",
            "|   Robert|Williams|\n",
            "|   Satish|  Kandel|\n",
            "+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By using col() function\n",
        "from pyspark.sql.functions import col\n",
        "df3.select(col(\"firstname\"),col(\"lastname\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3NzwE3WfWdS",
        "outputId": "32287a40-c357-44ea-9cd2-aa0417a91198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|    James|   Smith|\n",
            "|   Robert|Williams|\n",
            "|   Satish|  Kandel|\n",
            "+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select columns by regular expression\n",
        "df3.select(df3.colRegex(\"`^.*name*`\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6jrASUUfoSV",
        "outputId": "968f57d6-65e8-4431-ea64-59e52b497fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+\n",
            "|firstname|middlename|lastname|\n",
            "+---------+----------+--------+\n",
            "|    James|          |   Smith|\n",
            "|   Robert|          |Williams|\n",
            "|   Satish|          |  Kandel|\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting all the columns from the spark dataframe\n",
        "df3.select(*columns).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxjbxm_1f01e",
        "outputId": "8768a77e-0f87-4ce9-c0dd-770a07dd8bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.select([col for col in df.columns]).show()\n",
        "df3.select([col for col in df3.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqtx4cVTgAsS",
        "outputId": "fd3b43dc-7a94-4410-f7c2-45344318c289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.select(\"*\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L83zsYkzoIdF",
        "outputId": "a60c09a3-b308-4556-8e67-b0bde33e8fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|   Satish|          |  Kandel|1998-04-01|     M|  5000|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "selecting columns by index"
      ],
      "metadata": {
        "id": "AIjQME7FpUj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting first 3 columns and top 3 rows\n",
        "df3.select(df3.columns[:3]).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF60eYJdo19a",
        "outputId": "e627bb68-4deb-4b71-d29b-100acc25a9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+\n",
            "|firstname|middlename|lastname|\n",
            "+---------+----------+--------+\n",
            "|    James|          |   Smith|\n",
            "|   Robert|          |Williams|\n",
            "|   Satish|          |  Kandel|\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting columns 2 to 4  and top 3 rows\n",
        "df3.select(df3.columns[2:4]).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoXCSGY9pERJ",
        "outputId": "36e51bf2-8039-4d27-b7cf-36cce67d382b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+\n",
            "|lastname|       dob|\n",
            "+--------+----------+\n",
            "|   Smith|1991-04-01|\n",
            "|Williams|1978-09-05|\n",
            "|  Kandel|1998-04-01|\n",
            "+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grouping Data"
      ],
      "metadata": {
        "id": "f1mb_iGRpzJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([\n",
        "    ['red', 'banana', 1, 10],\n",
        "    ['blue', 'banana', 2, 20],\n",
        "    ['red', 'carrot', 3, 30],\n",
        "    ['blue', 'grape', 4, 40],\n",
        "    ['red', 'carrot', 5, 50],\n",
        "    ['black', 'carrot', 6, 60],\n",
        "    ['red', 'banana', 7, 70],\n",
        "    ['red', 'grape', 8, 80]],\n",
        "    schema=['color', 'fruit', 'v1', 'v2'])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_aTnPECpQkh",
        "outputId": "59a4d8dd-7772-447c-fcd5-c840e92aaaf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "+-----+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying avg() function\n",
        "df.groupby('color').avg().show()\n",
        "# this function applies avg function to each of the numerical columns as we can see average of  categorical column is not calculated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiULn0dPpnH6",
        "outputId": "f7a42421-d8d2-4e1a-9653-796cca58bd12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-------+\n",
            "|color|avg(v1)|avg(v2)|\n",
            "+-----+-------+-------+\n",
            "|  red|    4.8|   48.0|\n",
            "| blue|    3.0|   30.0|\n",
            "|black|    6.0|   60.0|\n",
            "+-----+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "problem:\n",
        "add or subtract value with the mean of the column for V1 and V2\n",
        "approach:\n",
        "write a function which will accept dataframe and perform operation on the dataframe\n",
        "'''\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "df.groupby('color').agg(F.avg('v1')).alias(\"avg_v1\").show()\n",
        "\n",
        "df_multiple_gb=df.groupby(['color','fruit']).agg(\n",
        "    F.avg('v1').alias(\"avg_v1\"),\n",
        "    F.avg('v2').alias(\"avg_v2\"),\n",
        "    F.sum('v1').alias(\"sum_v1\"),\n",
        "    F.sum('v2').alias(\"sum_v2\")\n",
        "  )\n",
        "\n",
        "df_multiple_gb.show()\n",
        "\n",
        "\n",
        "\n",
        "df.groupby(['color','fruit']).agg(F.avg('v1')).alias(\"avg_v1\").show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV-G1RmEp_Vn",
        "outputId": "9bf8379d-4059-4bd9-dd8d-776cedae621a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+\n",
            "|color|avg(v1)|\n",
            "+-----+-------+\n",
            "|  red|    4.8|\n",
            "| blue|    3.0|\n",
            "|black|    6.0|\n",
            "+-----+-------+\n",
            "\n",
            "+-----+------+------+------+------+------+\n",
            "|color| fruit|avg_v1|avg_v2|sum_v1|sum_v2|\n",
            "+-----+------+------+------+------+------+\n",
            "| blue| grape|   4.0|  40.0|     4|    40|\n",
            "|  red|banana|   4.0|  40.0|     8|    80|\n",
            "|  red|carrot|   4.0|  40.0|     8|    80|\n",
            "| blue|banana|   2.0|  20.0|     2|    20|\n",
            "|black|carrot|   6.0|  60.0|     6|    60|\n",
            "|  red| grape|   8.0|  80.0|     8|    80|\n",
            "+-----+------+------+------+------+------+\n",
            "\n",
            "+-----+------+-------+\n",
            "|color| fruit|avg(v1)|\n",
            "+-----+------+-------+\n",
            "| blue| grape|    4.0|\n",
            "|  red|banana|    4.0|\n",
            "|  red|carrot|    4.0|\n",
            "| blue|banana|    2.0|\n",
            "|black|carrot|    6.0|\n",
            "|  red| grape|    8.0|\n",
            "+-----+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6KkynoAZrOnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge and group by two dataframe"
      ],
      "metadata": {
        "id": "Ul-Mbbcgr7x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.createDataFrame(\n",
        "    [(20000101, 1, 1.0), (20000101, 2, 2.0), (20000102, 1, 3.0), (20000102, 2, 4.0)],\n",
        "    ('time', 'id', 'v1'))\n",
        "\n",
        "df2 = spark.createDataFrame(\n",
        "    [(20000101, 1, 'x'), (20000101, 2, 'y')],\n",
        "    ('time', 'id', 'v2'))\n"
      ],
      "metadata": {
        "id": "W0V-BZCxsA6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_ordered(l, r):\n",
        "    return pd.merge_ordered(l, r)\n",
        "\n",
        "df1.groupby('id').cogroup(df2.groupby('id')).applyInPandas(\n",
        "    merge_ordered, schema='time int, id int, v1 double, v2 string').show()"
      ],
      "metadata": {
        "id": "2APCeDmRsE39"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}